{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ge = np.array([])\n",
    "laplace_det = np.array([])\n",
    "nop = np.array([])\n",
    "sum_p_norm = np.array([])\n",
    "sum_s_norm = np.array([])\n",
    "sum_f_norm = np.array([])\n",
    "sampling_det = np.array([])\n",
    "path_norm = np.array([])\n",
    "sigma = np.array([])\n",
    "\n",
    "#,'tanh'\n",
    "for act in ['relu','tanh']:\n",
    "    for net in ['alexnet_1','alexnet_2','alexnet_3']:\n",
    "        fname = net+'_'+act+'/'\n",
    "        ge = np.append(ge,np.load(fname+'ge'+'.npy',allow_pickle=True))\n",
    "        laplace_det = np.append(laplace_det,np.load(fname+'laplace_det'+'.npy',allow_pickle=True))\n",
    "        nop = np.append(nop,np.load(fname+'nop'+'.npy',allow_pickle=True))\n",
    "        sum_p_norm = np.append(sum_p_norm,np.load(fname+'sum_p_norm'+'.npy',allow_pickle=True))\n",
    "        sum_s_norm = np.append(sum_s_norm,np.load(fname+'sum_s_norm'+'.npy',allow_pickle=True))\n",
    "        sum_f_norm = np.append(sum_f_norm,np.load(fname+'sum_f_norm'+'.npy',allow_pickle=True))\n",
    "        sampling_det = np.append(sampling_det,np.load(fname+'sampling_det'+'.npy',allow_pickle=True))\n",
    "        sigma = np.append(sigma,np.load(fname+'sigma'+'.npy',allow_pickle=True))          \n",
    "        path_norm = np.append(path_norm,np.load(fname+'path_norm'+'.npy',allow_pickle=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall(a,b):\n",
    "    b = np.array(b)\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for i in range(len(a)-1):\n",
    "        for j in range(i+1,len(a)):\n",
    "            if (a[i]-a[j])*(b[i]-b[j])>0:\n",
    "                pos += 1\n",
    "            elif (a[i]-a[j])*(b[i]-b[j])<0:\n",
    "                neg += 1\n",
    "    if pos+neg == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (pos-neg)/(pos+neg)\n",
    "\n",
    "def mi(a,b):\n",
    "    b = np.array(b)\n",
    "    index = np.arange(len(a))\n",
    "    np.random.shuffle(index)\n",
    "    a = a[index]\n",
    "    b = b[index]\n",
    "    h1 = 0\n",
    "    h2 = 0\n",
    "    h3 = 0\n",
    "    h4 = 0\n",
    "    for i in range(len(a)-1):\n",
    "        for j in range(i+1,len(a)):\n",
    "            if (a[i]-a[j])>0 and (b[i]-b[j])>0.0001:\n",
    "                h1 += 1\n",
    "            elif (a[i]-a[j])>0 and (b[i]-b[j])<-0.0001:\n",
    "                h2 += 1\n",
    "            elif (a[i]-a[j])<0 and (b[i]-b[j])>0.0001:\n",
    "                h3 += 1\n",
    "            elif (a[i]-a[j])<0 and (b[i]-b[j])<-0.0001:\n",
    "                h4 += 1\n",
    "    h_all = h1+h2+h3+h4\n",
    "    if h_all==0:\n",
    "        return 0\n",
    "    else:\n",
    "        p1 = h1/h_all\n",
    "        p2 = h2/h_all\n",
    "        p3 = h3/h_all\n",
    "        p4 = h4/h_all\n",
    "        mi = 0\n",
    "        if p1>0.:\n",
    "            mi += p1*np.log2(p1/((p1+p2)*(p1+p3))) \n",
    "        if p2>0.:\n",
    "            mi += p2*np.log2(p2/((p1+p2)*(p2+p4))) \n",
    "        if p3>0.:\n",
    "            mi += p3*np.log2(p3/((p3+p4)*(p1+p3))) \n",
    "        if p4>0.:\n",
    "            mi += p4*np.log2(p4/((p3+p4)*(p2+p4)))\n",
    "        return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subset2(ij):\n",
    "    lr_ = [0.1, 0.03]\n",
    "    drop_rate_ = [0.0, 0.15, 0.3]\n",
    "    width_ = [1., 0.5]\n",
    "    batch_size_ = [64, 256]\n",
    "    weight_decay_ = [0.0, 0.0005]\n",
    "\n",
    "    all_co = []\n",
    "    all_mi = []\n",
    "\n",
    "    all_co_act = []\n",
    "    all_mi_act = []\n",
    "    all_co_net = []\n",
    "    all_mi_net = []\n",
    "    all_co_weight_decay = []\n",
    "    all_mi_weight_decay = []\n",
    "    all_co_drop_rate = []\n",
    "    all_mi_drop_rate = []\n",
    "    all_co_width = []\n",
    "    all_mi_width = []\n",
    "    all_co_batch_size = []\n",
    "    all_mi_batch_size = []\n",
    "    all_co_lr = []\n",
    "    all_mi_lr = []\n",
    "    for ii in range(5):\n",
    "        for jj in range(ii+1,6):\n",
    "            i = 0\n",
    "            dic_ge = dict()\n",
    "            dic_laplace_det = dict()\n",
    "            dic_nop = dict()\n",
    "            dic_sum_p_norm = dict()\n",
    "            dic_sum_s_norm = dict()\n",
    "            dic_sum_f_norm = dict()\n",
    "            dic_sampling_det = dict()\n",
    "            dic_sigma = dict()\n",
    "            dic_path_norm = dict()\n",
    "\n",
    "            dic_act = dict()\n",
    "            dic_net = dict()\n",
    "            dic_weight_decay = dict()\n",
    "            dic_drop_rate = dict()\n",
    "            dic_width = dict()\n",
    "            dic_batch_size = dict()\n",
    "            dic_lr = dict()\n",
    "            for act in ['relu','tanh']:\n",
    "                for net in ['alexnet_1','alexnet_2','alexnet_3']:\n",
    "                    for weight_decay in [0.0, 0.0005]:\n",
    "                        for drop_rate in [0.0, 0.15, 0.3]:\n",
    "                            for width in [1., 0.5]:\n",
    "                                for batch_size in [64, 256]:\n",
    "                                    for lr in [0.1, 0.03]:\n",
    "                                        sub = [act, net, weight_decay, width, batch_size, lr]\n",
    "                                        sub_a = str(sub[ii])\n",
    "                                        sub_b = str(sub[jj])\n",
    "\n",
    "                                        if sub_a+sub_b in dic_ge.keys():\n",
    "                                            dic_laplace_det[sub_a+sub_b].append(laplace_det[i])\n",
    "                                            dic_nop[sub_a+sub_b].append(nop[i])\n",
    "                                            dic_ge[sub_a+sub_b].append(ge[i])\n",
    "                                            dic_sum_p_norm[sub_a+sub_b].append(sum_p_norm[i])\n",
    "                                            dic_sum_s_norm[sub_a+sub_b].append(sum_s_norm[i])\n",
    "                                            dic_sum_f_norm[sub_a+sub_b].append(sum_f_norm[i])\n",
    "                                            dic_sampling_det[sub_a+sub_b].append(sampling_det[i])\n",
    "                                            dic_sigma[sub_a+sub_b].append(sigma[i])\n",
    "                                            dic_path_norm[sub_a+sub_b].append(path_norm[i])\n",
    "\n",
    "                                            dic_act[sub_a+sub_b].append(ord(act[0]))\n",
    "                                            dic_net[sub_a+sub_b].append(ord(net[-1]))\n",
    "                                            dic_weight_decay[sub_a+sub_b].append(weight_decay)\n",
    "                                            dic_drop_rate[sub_a+sub_b].append(drop_rate)\n",
    "                                            dic_width[sub_a+sub_b].append(width)\n",
    "                                            dic_batch_size[sub_a+sub_b].append(batch_size)\n",
    "                                            dic_lr[sub_a+sub_b].append(lr)\n",
    "                                        else:\n",
    "                                            dic_laplace_det[sub_a+sub_b] = [laplace_det[i]]\n",
    "                                            dic_nop[sub_a+sub_b] = [nop[i]]\n",
    "                                            dic_ge[sub_a+sub_b] = [ge[i]]\n",
    "                                            dic_sum_p_norm[sub_a+sub_b] = [sum_p_norm[i]]\n",
    "                                            dic_sum_s_norm[sub_a+sub_b] = [sum_s_norm[i]]\n",
    "                                            dic_sum_f_norm[sub_a+sub_b] = [sum_f_norm[i]]\n",
    "                                            dic_sampling_det[sub_a+sub_b] = [sampling_det[i]]\n",
    "                                            dic_sigma[sub_a+sub_b] = [sigma[i]]\n",
    "                                            dic_path_norm[sub_a+sub_b] = [path_norm[i]]\n",
    "\n",
    "                                            dic_act[sub_a+sub_b] = [ord(act[0])]\n",
    "                                            dic_net[sub_a+sub_b] = [ord(net[-1])]\n",
    "                                            dic_weight_decay[sub_a+sub_b] = [weight_decay]\n",
    "                                            dic_drop_rate[sub_a+sub_b] = [drop_rate]\n",
    "                                            dic_width[sub_a+sub_b] = [width]\n",
    "                                            dic_batch_size[sub_a+sub_b] = [batch_size]\n",
    "                                            dic_lr[sub_a+sub_b] = [lr]\n",
    "                                        i += 1   \n",
    "            sub_name = ['act', 'net', 'weight_decay', 'width', 'batch_size', 'lr']\n",
    "            co = []\n",
    "            m_i = []\n",
    "\n",
    "            co_act = []\n",
    "            m_i_act = []\n",
    "            co_net = []\n",
    "            m_i_net = []\n",
    "            co_weight_decay = []\n",
    "            m_i_weight_decay = []\n",
    "            co_drop_rate = []\n",
    "            m_i_drop_rate = []\n",
    "            co_width = []\n",
    "            m_i_width = []\n",
    "            co_batch_size = []\n",
    "            m_i_batch_size = []\n",
    "            co_lr = []\n",
    "            m_i_lr = []\n",
    "\n",
    "            for key in dic_ge:\n",
    "                #test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000) + np.log2(1/np.array(dic_sampling_det[key]))\n",
    "\n",
    "                #test_m = np.array(np.log2(1/np.array(dic_sampling_det[key])))\n",
    "                if ij == 1:\n",
    "                    test_m = np.array(dic_sum_f_norm[key])   \n",
    "                elif ij == 2:\n",
    "                    test_m = np.array(dic_sum_s_norm[key])\n",
    "                elif ij == 3:\n",
    "                    test_m = np.array(dic_sum_p_norm[key])\n",
    "                elif ij == 4:\n",
    "                    test_m = np.array(dic_path_norm[key])\n",
    "                elif ij == 5:\n",
    "                    test_m = np.array(dic_sigma[key])*2*np.log2(2*np.array(dic_nop[key]))\n",
    "                elif ij == 6:\n",
    "                    test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000)\n",
    "                elif ij == 7:\n",
    "                    test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000) + np.log2(1/np.array(dic_laplace_det[key]))\n",
    "                elif ij == 8:\n",
    "                    test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000) + np.log2(1/np.array(dic_sampling_det[key]))\n",
    "\n",
    "                co.append(kendall(test_m,dic_ge[key]))\n",
    "                m_i.append(mi(test_m,dic_ge[key]))\n",
    "\n",
    "                '''if 'act' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_act.append(kendall(test_m,dic_act[key]))\n",
    "                    m_i_act.append(mi(test_m,dic_act[key]))\n",
    "                if 'net' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_net.append(kendall(test_m,dic_net[key]))\n",
    "                    m_i_net.append(mi(test_m,dic_net[key]))\n",
    "                if 'weight_decay' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_weight_decay.append(kendall(test_m,dic_weight_decay[key]))\n",
    "                    m_i_weight_decay.append(mi(test_m,dic_weight_decay[key]))\n",
    "                if 'drop_rate' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_drop_rate.append(kendall(test_m,dic_drop_rate[key]))\n",
    "                    m_i_drop_rate.append(mi(test_m,dic_drop_rate[key]))\n",
    "                if 'width' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_width.append(kendall(test_m,dic_width[key]))\n",
    "                    m_i_width.append(mi(test_m,dic_width[key]))\n",
    "                if 'batch_size' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_batch_size.append(kendall(test_m,dic_batch_size[key]))\n",
    "                    m_i_batch_size.append(mi(test_m,dic_batch_size[key]))\n",
    "                if 'lr' not in [sub_name[ii], sub_name[jj]]:\n",
    "                    co_lr.append(kendall(test_m,dic_lr[key]))\n",
    "                    m_i_lr.append(mi(test_m,dic_lr[key]))'''\n",
    "\n",
    "            #print(sub_name[ii]+'_'+sub_name[jj])\n",
    "            #print('corr ',np.mean(co)) \n",
    "            #print('mi ',np.mean(m_i)) \n",
    "            all_co.append(np.mean(co))\n",
    "            all_mi.append(np.mean(m_i))\n",
    "\n",
    "            '''if len(co_act)>0:\n",
    "                all_co_act.append(np.mean(co_act))\n",
    "                all_mi_act.append(np.mean(m_i_act))\n",
    "            if len(co_net)>0:\n",
    "                all_co_net.append(np.mean(co_net))\n",
    "                all_mi_net.append(np.mean(m_i_net))\n",
    "            if len(co_weight_decay)>0:\n",
    "                all_co_weight_decay.append(np.mean(co_weight_decay))\n",
    "                all_mi_weight_decay.append(np.mean(m_i_weight_decay))\n",
    "            if len(co_drop_rate)>0:\n",
    "                all_co_drop_rate.append(np.mean(co_drop_rate))\n",
    "                all_mi_drop_rate.append(np.mean(m_i_drop_rate))\n",
    "            if len(co_width)>0:\n",
    "                all_co_width.append(np.mean(co_width))\n",
    "                all_mi_width.append(np.mean(m_i_width))\n",
    "            if len(co_batch_size)>0:\n",
    "                all_co_batch_size.append(np.mean(co_batch_size))\n",
    "                all_mi_batch_size.append(np.mean(m_i_batch_size))\n",
    "            if len(co_lr)>0:\n",
    "                all_co_lr.append(np.mean(co_lr))\n",
    "                all_mi_lr.append(np.mean(m_i_lr))'''\n",
    "\n",
    "    pr_co = []\n",
    "    pr_mi = []\n",
    "\n",
    "    '''cco = np.mean(all_co_batch_size) \n",
    "    mmi = np.mean(all_mi_batch_size) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_lr)\n",
    "    mmi = np.mean(all_mi_lr) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_net)\n",
    "    mmi = np.mean(all_mi_net) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_act)\n",
    "    mmi = np.mean(all_mi_act)\n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_weight_decay)\n",
    "    mmi = np.mean(all_mi_weight_decay) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_width) \n",
    "    mmi = np.mean(all_mi_width) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)\n",
    "\n",
    "    cco = np.mean(all_co_drop_rate)\n",
    "    mmi = np.mean(all_mi_drop_rate) \n",
    "    pr_co.append('%.4f' % cco)\n",
    "    pr_mi.append('%.4f' % mmi)'''\n",
    "\n",
    "    cco = np.mean(all_co)\n",
    "    mmi = np.mean(all_mi) \n",
    "    pr_co.append(cco)\n",
    "    pr_mi.append(mmi)\n",
    "\n",
    "    return all_mi, pr_mi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########w==1###################\n",
    "def subset1(ij):\n",
    "    lr_ = [0.1, 0.03]\n",
    "    drop_rate_ = [0.0, 0.15, 0.3]\n",
    "    width_ = [1., 0.5]\n",
    "    batch_size_ = [64, 256]\n",
    "    weight_decay_ = [0.0, 0.0005]\n",
    "\n",
    "    all_co = []\n",
    "    all_mi = []\n",
    "\n",
    "    all_co_act = []\n",
    "    all_mi_act = []\n",
    "    all_co_net = []\n",
    "    all_mi_net = []\n",
    "    all_co_weight_decay = []\n",
    "    all_mi_weight_decay = []\n",
    "    all_co_drop_rate = []\n",
    "    all_mi_drop_rate = []\n",
    "    all_co_width = []\n",
    "    all_mi_width = []\n",
    "    all_co_batch_size = []\n",
    "    all_mi_batch_size = []\n",
    "    all_co_lr = []\n",
    "    all_mi_lr = []\n",
    "    for ii in range(6):\n",
    "        i = 0\n",
    "        dic_ge = dict()\n",
    "        dic_laplace_det = dict()\n",
    "        dic_nop = dict()\n",
    "        dic_sum_p_norm = dict()\n",
    "        dic_sum_s_norm = dict()\n",
    "        dic_sum_f_norm = dict()\n",
    "        dic_sampling_det = dict()\n",
    "        dic_sigma = dict()\n",
    "        dic_path_norm = dict()\n",
    "\n",
    "        dic_act = dict()\n",
    "        dic_net = dict()\n",
    "        dic_weight_decay = dict()\n",
    "        dic_drop_rate = dict()\n",
    "        dic_width = dict()\n",
    "        dic_batch_size = dict()\n",
    "        dic_lr = dict()\n",
    "        for act in ['relu','tanh']:\n",
    "            for net in ['vgg11','vgg16','vgg19']:\n",
    "                for weight_decay in [0.0, 0.0005]:\n",
    "                    for drop_rate in [0.0, 0.15, 0.3]:\n",
    "                        for width in [1., 0.5]:\n",
    "                            for batch_size in [64, 256]:\n",
    "                                for lr in [0.1, 0.03]:\n",
    "                                    sub = [act, net, weight_decay, width, batch_size, lr]\n",
    "                                    sub_a = str(sub[ii])\n",
    "                                    jj = ii\n",
    "                                    sub_b = str(sub[jj])\n",
    "\n",
    "                                    if sub_a+sub_b in dic_ge.keys():\n",
    "                                        dic_laplace_det[sub_a+sub_b].append(laplace_det[i])\n",
    "                                        dic_nop[sub_a+sub_b].append(nop[i])\n",
    "                                        dic_ge[sub_a+sub_b].append(ge[i])\n",
    "                                        dic_sum_p_norm[sub_a+sub_b].append(sum_p_norm[i])\n",
    "                                        dic_sum_s_norm[sub_a+sub_b].append(sum_s_norm[i])\n",
    "                                        dic_sum_f_norm[sub_a+sub_b].append(sum_f_norm[i])\n",
    "                                        dic_sampling_det[sub_a+sub_b].append(sampling_det[i])\n",
    "                                        dic_sigma[sub_a+sub_b].append(sigma[i])\n",
    "                                        dic_path_norm[sub_a+sub_b].append(path_norm[i])\n",
    "\n",
    "                                        dic_act[sub_a+sub_b].append(ord(act[0]))\n",
    "                                        dic_net[sub_a+sub_b].append(ord(net[-1]))\n",
    "                                        dic_weight_decay[sub_a+sub_b].append(weight_decay)\n",
    "                                        dic_drop_rate[sub_a+sub_b].append(drop_rate)\n",
    "                                        dic_width[sub_a+sub_b].append(width)\n",
    "                                        dic_batch_size[sub_a+sub_b].append(batch_size)\n",
    "                                        dic_lr[sub_a+sub_b].append(lr)\n",
    "                                    else:\n",
    "                                        dic_laplace_det[sub_a+sub_b] = [laplace_det[i]]\n",
    "                                        dic_nop[sub_a+sub_b] = [nop[i]]\n",
    "                                        dic_ge[sub_a+sub_b] = [ge[i]]\n",
    "                                        dic_sum_p_norm[sub_a+sub_b] = [sum_p_norm[i]]\n",
    "                                        dic_sum_s_norm[sub_a+sub_b] = [sum_s_norm[i]]\n",
    "                                        dic_sum_f_norm[sub_a+sub_b] = [sum_f_norm[i]]\n",
    "                                        dic_sampling_det[sub_a+sub_b] = [sampling_det[i]]\n",
    "                                        dic_sigma[sub_a+sub_b] = [sigma[i]]\n",
    "                                        dic_path_norm[sub_a+sub_b] = [path_norm[i]]\n",
    "\n",
    "                                        dic_act[sub_a+sub_b] = [ord(act[0])]\n",
    "                                        dic_net[sub_a+sub_b] = [ord(net[-1])]\n",
    "                                        dic_weight_decay[sub_a+sub_b] = [weight_decay]\n",
    "                                        dic_drop_rate[sub_a+sub_b] = [drop_rate]\n",
    "                                        dic_width[sub_a+sub_b] = [width]\n",
    "                                        dic_batch_size[sub_a+sub_b] = [batch_size]\n",
    "                                        dic_lr[sub_a+sub_b] = [lr]\n",
    "                                    i += 1   \n",
    "        sub_name = ['act', 'net', 'weight_decay', 'width', 'batch_size', 'lr']\n",
    "        co = []\n",
    "        m_i = []\n",
    "\n",
    "        co_act = []\n",
    "        m_i_act = []\n",
    "        co_net = []\n",
    "        m_i_net = []\n",
    "        co_weight_decay = []\n",
    "        m_i_weight_decay = []\n",
    "        co_drop_rate = []\n",
    "        m_i_drop_rate = []\n",
    "        co_width = []\n",
    "        m_i_width = []\n",
    "        co_batch_size = []\n",
    "        m_i_batch_size = []\n",
    "        co_lr = []\n",
    "        m_i_lr = []\n",
    "\n",
    "        for key in dic_ge:\n",
    "            if ij == 1:\n",
    "                test_m = np.array(dic_sum_f_norm[key])   \n",
    "            elif ij == 2:\n",
    "                test_m = np.array(dic_sum_s_norm[key])\n",
    "            elif ij == 3:\n",
    "                test_m = np.array(dic_sum_p_norm[key])\n",
    "            elif ij == 4:\n",
    "                test_m = np.array(dic_path_norm[key])\n",
    "            elif ij == 5:\n",
    "                test_m = np.array(dic_sigma[key])*2*np.log2(2*np.array(dic_nop[key]))\n",
    "            elif ij == 6:\n",
    "                test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000)\n",
    "            elif ij == 7:\n",
    "                test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000) + np.log2(1/np.array(dic_laplace_det[key]))\n",
    "            elif ij == 8:\n",
    "                test_m = np.array(dic_sum_f_norm[key])/(np.array(dic_sigma[key])*150000) + np.log2(1/np.array(dic_sampling_det[key]))\n",
    "\n",
    "            co.append(kendall(test_m,dic_ge[key]))\n",
    "            m_i.append(mi(test_m,dic_ge[key]))\n",
    "\n",
    "            if 'act' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_act.append(kendall(test_m,dic_act[key]))\n",
    "                m_i_act.append(mi(test_m,dic_act[key]))\n",
    "            if 'net' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_net.append(kendall(test_m,dic_net[key]))\n",
    "                m_i_net.append(mi(test_m,dic_net[key]))\n",
    "            if 'weight_decay' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_weight_decay.append(kendall(test_m,dic_weight_decay[key]))\n",
    "                m_i_weight_decay.append(mi(test_m,dic_weight_decay[key]))\n",
    "            if 'drop_rate' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_drop_rate.append(kendall(test_m,dic_drop_rate[key]))\n",
    "                m_i_drop_rate.append(mi(test_m,dic_drop_rate[key]))\n",
    "            if 'width' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_width.append(kendall(test_m,dic_width[key]))\n",
    "                m_i_width.append(mi(test_m,dic_width[key]))\n",
    "            if 'batch_size' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_batch_size.append(kendall(test_m,dic_batch_size[key]))\n",
    "                m_i_batch_size.append(mi(test_m,dic_batch_size[key]))\n",
    "            if 'lr' not in [sub_name[ii], sub_name[jj]]:\n",
    "                co_lr.append(kendall(test_m,dic_lr[key]))\n",
    "                m_i_lr.append(mi(test_m,dic_lr[key]))\n",
    "\n",
    "        #print(sub_name[ii]+'_'+sub_name[jj])\n",
    "        #print('corr ',np.mean(co)) \n",
    "        #print('mi ',np.mean(m_i)) \n",
    "        all_co.append(np.mean(co))\n",
    "        all_mi.append(np.mean(m_i))\n",
    "\n",
    "        if len(co_act)>0:\n",
    "            all_co_act.append(np.mean(co_act))\n",
    "            all_mi_act.append(np.mean(m_i_act))\n",
    "        if len(co_net)>0:\n",
    "            all_co_net.append(np.mean(co_net))\n",
    "            all_mi_net.append(np.mean(m_i_net))\n",
    "        if len(co_weight_decay)>0:\n",
    "            all_co_weight_decay.append(np.mean(co_weight_decay))\n",
    "            all_mi_weight_decay.append(np.mean(m_i_weight_decay))\n",
    "        if len(co_drop_rate)>0:\n",
    "            all_co_drop_rate.append(np.mean(co_drop_rate))\n",
    "            all_mi_drop_rate.append(np.mean(m_i_drop_rate))\n",
    "        if len(co_width)>0:\n",
    "            all_co_width.append(np.mean(co_width))\n",
    "            all_mi_width.append(np.mean(m_i_width))\n",
    "        if len(co_batch_size)>0:\n",
    "            all_co_batch_size.append(np.mean(co_batch_size))\n",
    "            all_mi_batch_size.append(np.mean(m_i_batch_size))\n",
    "        if len(co_lr)>0:\n",
    "            all_co_lr.append(np.mean(co_lr))\n",
    "            all_mi_lr.append(np.mean(m_i_lr))\n",
    "\n",
    "    pr_co = []\n",
    "    pr_mi = []\n",
    "\n",
    "\n",
    "    cco = np.mean(all_co)\n",
    "    mmi = np.mean(all_mi) \n",
    "    pr_co.append(cco)\n",
    "    pr_mi.append(mmi)\n",
    "\n",
    "    return all_mi, pr_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########w==0###################\n",
    "def subset0(ij):\n",
    "    if ij == 1:\n",
    "        test_m = np.array(sum_f_norm)   \n",
    "    elif ij == 2:\n",
    "        test_m = np.array(sum_s_norm)\n",
    "    elif ij == 3:\n",
    "        test_m = np.array(sum_p_norm)\n",
    "    elif ij == 4:\n",
    "        test_m = np.array(path_norm)\n",
    "    elif ij == 5:\n",
    "        test_m = np.array(sigma)*2*np.log2(2*np.array(nop))\n",
    "    elif ij == 6:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000)\n",
    "    elif ij == 7:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000) + np.log2(1/np.array(laplace_det))\n",
    "    elif ij == 8:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000) + np.log2(1/np.array(sampling_det))\n",
    "\n",
    "    return (mi(test_m,ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mi2(a,b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    index = np.arange(len(a))\n",
    "    np.random.shuffle(index)\n",
    "    a = a[index]\n",
    "    b = b[index]\n",
    "    h1 = 0\n",
    "    h2 = 0\n",
    "    h3 = 0\n",
    "    h4 = 0\n",
    "    for i in range(len(a)-1):\n",
    "        for j in range(i+1,len(a)):\n",
    "            if (a[i]-a[j])>0 and (b[i]-b[j])>0:\n",
    "                h1 += 1\n",
    "            elif (a[i]-a[j])>0 and (b[i]-b[j])<0:\n",
    "                h2 += 1\n",
    "            elif (a[i]-a[j])<0 and (b[i]-b[j])>0:\n",
    "                h3 += 1\n",
    "            elif (a[i]-a[j])<0 and (b[i]-b[j])<0:\n",
    "                h4 += 1\n",
    "    h_all = h1+h2+h3+h4\n",
    "    if h_all == 0:\n",
    "        return 10\n",
    "    else:\n",
    "        p1 = h1/h_all\n",
    "        p2 = h2/h_all\n",
    "        p3 = h3/h_all\n",
    "        p4 = h4/h_all\n",
    "        mi = 0\n",
    "        if p1>0.:\n",
    "            mi += p1*np.log2(p1/((p1+p2)*(p1+p3))) \n",
    "        if p2>0.:\n",
    "            mi += p2*np.log2(p2/((p1+p2)*(p2+p4))) \n",
    "        if p3>0.:\n",
    "            mi += p3*np.log2(p3/((p3+p4)*(p1+p3))) \n",
    "        if p4>0.:\n",
    "            mi += p4*np.log2(p4/((p3+p4)*(p2+p4)))\n",
    "        return mi\n",
    "    \n",
    "def co_parameter(ii,jj,co):\n",
    "    coo = []\n",
    "    co_ = []\n",
    "    tar = []\n",
    "    for i in range(int(288/ii)):\n",
    "        for j in range(int(ii/jj)):\n",
    "            if jj==2:\n",
    "                co_.append(co[i*ii+j])\n",
    "                co_.append(co[int(i*ii+j+ii/jj)])\n",
    "                tar.append(1)\n",
    "                tar.append(2)\n",
    "            if jj==3:\n",
    "                co_.append(co[i*ii+j])\n",
    "                co_.append(co[int(i*ii+j+ii/jj)])\n",
    "                co_.append(co[int(i*ii+j+2*ii/jj)])\n",
    "                tar.append(1)\n",
    "                tar.append(2)\n",
    "                tar.append(3)\n",
    "            \n",
    "            if len(co_)==12:\n",
    "                cco = mi2(co_,tar)\n",
    "                if cco<2:\n",
    "                    coo.append(cco)\n",
    "                co_ = []\n",
    "                tar = []\n",
    "    return np.mean(coo)\n",
    "\n",
    "def subco(ij):\n",
    "    co = []\n",
    "\n",
    "    if ij == 1:\n",
    "        test_m = np.array(sum_f_norm)   \n",
    "    elif ij == 2:\n",
    "        test_m = np.array(sum_s_norm)\n",
    "    elif ij == 3:\n",
    "        test_m = np.array(sum_p_norm)\n",
    "    elif ij == 4:\n",
    "        test_m = np.array(path_norm)\n",
    "    elif ij == 5:\n",
    "        test_m = np.array(sigma)*2*np.log2(2*np.array(nop))\n",
    "    elif ij == 6:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000)\n",
    "    elif ij == 7:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000) + np.log2(1/np.array(laplace_det))\n",
    "    elif ij == 8:\n",
    "        test_m = np.array(sum_f_norm)/(np.array(sigma)*150000) + np.log2(1/np.array(sampling_det))\n",
    "\n",
    "    co.append(co_parameter(4,2,test_m))\n",
    "    co.append(co_parameter(2,2,test_m))\n",
    "    co.append(co_parameter(144,3,test_m))\n",
    "    co.append(co_parameter(288,2,test_m))\n",
    "    co.append(co_parameter(48,2,test_m))\n",
    "    co.append(co_parameter(8,2,test_m))\n",
    "    co.append(co_parameter(24,2,test_m))\n",
    "\n",
    "    return co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& Frob Distance & 0.1832 & 0.2565 & 0.3705 & 0.0732 & 0.1677 & 0.4874 & 0.0644 & 0.0289 & 0.0159 & 0.0094\\\\\n",
      "& Spectral Norm & 0.2527 & 0.3155 & 0.2482 & 0.1090 & 0.7924 & 0.2163 & 0.1259 & 0.0937 & 0.0932 & 0.0986\\\\\n",
      "& Parameter Norm & 0.2461 & 0.3109 & 0.1363 & 0.1039 & 0.8968 & 0.1982 & 0.0583 & 0.0927 & 0.0865 & 0.0826\\\\\n",
      "& Path Norm & 0.2325 & 0.1854 & 0.2543 & 0.5054 & 0.2787 & 0.2073 & 0.1530 & 0.0425 & 0.0307 & 0.0177\\\\\n",
      "& Sharpness $\\alpha'$ & 0.1238 & 0.0728 & 0.2038 & 0.5561 & 0.3633 & 0.3128 & 0.1583 & 0.0877 & 0.0639 & 0.0418\\\\\n",
      "& \\textbf{Pac-Sharpness} & 0.1518 & 0.3286 & 0.0468 & 0.5185 & 0.4043 & 0.1112 & 0.1277 & 0.0552 & 0.0324 & 0.0097\\\\\n",
      "& \\textbf{Pac-S(Laplace)} & 0.0630 & 0.1164 & 0.0805 & 0.2851 & 0.3425 & 0.0306 & 0.7325 & 0.1248 & 0.1123 & 0.1052\\\\\n",
      "& \\textbf{Pac-S(Sampling)} & 0.3059 & 0.1739 & 0.2552 & 0.2163 & 0.3663 & 0.1382 & 0.4299 & 0.1012 & 0.0712 & 0.0466\\\\\n",
      "############################################################################\n",
      "& Frob Distance & 0.0205 & 0.0108 & 0.0613 & 0.0200 & 0.0372 & 0.0042 & 0.0370 & 0.0054 & 0.0196 & 0.0849 & 0.0203 & 0.0179 & 0.0312 & 0.0484 & 0.0125\\\\\n",
      "& Spectral Norm & 0.1122 & 0.0589 & 0.1840 & 0.1376 & 0.1304 & 0.0071 & 0.1256 & 0.0688 & 0.0733 & 0.0810 & 0.0302 & 0.0319 & 0.1317 & 0.1331 & 0.0931\\\\\n",
      "& Parameter Norm & 0.1323 & 0.0396 & 0.1891 & 0.1349 & 0.1345 & 0.0234 & 0.1163 & 0.0649 & 0.0700 & 0.1005 & 0.0346 & 0.0376 & 0.1229 & 0.1144 & 0.0707\\\\\n",
      "& Path Norm & 0.0141 & 0.0461 & 0.0039 & 0.0190 & 0.0096 & 0.0624 & 0.0434 & 0.0378 & 0.0304 & 0.1295 & 0.0800 & 0.0702 & 0.0495 & 0.0280 & 0.0485\\\\\n",
      "& Sharpness $\\alpha'$ & 0.1182 & 0.1120 & 0.1504 & 0.1168 & 0.1194 & 0.0828 & 0.0447 & 0.0384 & 0.0452 & 0.1046 & 0.0876 & 0.0890 & 0.0740 & 0.0734 & 0.0673\\\\\n",
      "& \\textbf{Pac-Sharpness} & 0.1222 & 0.0727 & 0.0824 & 0.0992 & 0.1019 & 0.0534 & 0.0161 & 0.0260 & 0.0247 & 0.0369 & 0.0575 & 0.0807 & 0.0188 & 0.0143 & 0.0338\\\\\n",
      "& \\textbf{Pac-S(Laplace)} & 0.1616 & 0.0960 & 0.1322 & 0.1299 & 0.1214 & 0.1183 & 0.1730 & 0.1511 & 0.1391 & 0.0974 & 0.0895 & 0.0810 & 0.1326 & 0.1242 & 0.1122\\\\\n",
      "& \\textbf{Pac-S(Sampling)} & 0.1275 & 0.1125 & 0.0547 & 0.0659 & 0.0866 & 0.2009 & 0.0939 & 0.1069 & 0.1405 & 0.1144 & 0.1260 & 0.1589 & 0.0296 & 0.0459 & 0.0582\\\\\n",
      "\n",
      "############################################################################\n",
      "& Frob Distance & 0.0219 & 0.0085 & 0.0059 & 0.0380 & 0.0061 & 0.0138\\\\\n",
      "& Spectral Norm & 0.1320 & 0.0774 & 0.0317 & 0.1363 & 0.0939 & 0.0934\\\\\n",
      "& Parameter Norm & 0.1381 & 0.0725 & 0.0303 & 0.1219 & 0.0779 & 0.0778\\\\\n",
      "& Path Norm & 0.0070 & 0.0212 & 0.0751 & 0.0315 & 0.0344 & 0.0173\\\\\n",
      "& Sharpness $\\alpha'$ & 0.1112 & 0.0272 & 0.0770 & 0.0633 & 0.0503 & 0.0530\\\\\n",
      "& \\textbf{Pac-Sharpness} & 0.0953 & 0.0128 & 0.0381 & 0.0083 & 0.0194 & 0.0165\\\\\n",
      "& \\textbf{Pac-S(Laplace)} & 0.1165 & 0.1378 & 0.0796 & 0.1226 & 0.1096 & 0.1081\\\\\n",
      "& \\textbf{Pac-S(Sampling)} & 0.0632 & 0.1061 & 0.1196 & 0.0325 & 0.0424 & 0.0612\\\\\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prt(iii):\n",
    "    if iii==1:\n",
    "        print('& Frob Distance & ', end='')\n",
    "    elif iii==2:\n",
    "        print('& Spectral Norm & ', end='') \n",
    "    elif iii==3:\n",
    "        print('& Parameter Norm & ', end='')\n",
    "    elif iii==4:\n",
    "        print('& Path Norm & ', end='')\n",
    "    elif iii==5:\n",
    "        print('& Sharpness $\\\\alpha\\'$ & ', end='')\n",
    "    elif iii==6:\n",
    "        print('& \\\\textbf{Pac-Sharpness} & ', end='')\n",
    "    elif iii==7:\n",
    "        print('& \\\\textbf{Pac-S(Laplace)} & ', end='')\n",
    "    elif iii==8:\n",
    "        print('& \\\\textbf{Pac-S(Sampling)} & ', end='')\n",
    "        \n",
    "for iii in range(1,9):\n",
    "    prt(iii)\n",
    "    b = subco(iii)\n",
    "    for x in b:\n",
    "        print(\"%.4f\" % x, end = ' & ')\n",
    "\n",
    "    a2, b2 = subset2(iii)\n",
    "    print(\"%.4f\" % b2[0], end = ' & ')\n",
    "\n",
    "    a1, b1 = subset1(iii)\n",
    "    print(\"%.4f\" % b1[0], end = ' & ')\n",
    "\n",
    "    b0 = subset0(iii)\n",
    "    print(\"%.4f\" % b0, end='\\\\\\\\')\n",
    "    print('')\n",
    "\n",
    "print('############################################################################')\n",
    "for iii in range(1,9):\n",
    "    prt(iii)\n",
    "    a2, b2 = subset2(iii)\n",
    "    for jjj in range(len(a2)-1):\n",
    "        print(\"%.4f\" % a2[jjj], end = ' & ')\n",
    "    print(\"%.4f\" % a2[-1], end='\\\\\\\\')\n",
    "    print('')\n",
    "\n",
    "print('')\n",
    "print('############################################################################')\n",
    "for iii in range(1,9):\n",
    "    prt(iii)\n",
    "    a1, b1 = subset1(iii)\n",
    "    for jjj in range(len(a1)-1):\n",
    "        print(\"%.4f\" % a1[jjj], end = ' & ')\n",
    "    print(\"%.4f\" % a1[-1], end='\\\\\\\\')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
